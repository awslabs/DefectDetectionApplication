{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d677e71b-add2-4665-8bb6-ac1b551ab083",
   "metadata": {},
   "source": [
    "# AWS IoT Greengrass Model Component Setup for DDA\n",
    "\n",
    "This notebook automates the creation of AWS IoT Greengrass model components for the Defect Detection Application (DDA). The process includes:\n",
    "\n",
    "1. **Model Artifact Processing**: Download and prepare trained model artifacts\n",
    "2. **Directory Structure Setup**: Organize files for Greengrass deployment\n",
    "3. **Component Creation**: Generate and deploy Greengrass model components\n",
    "\n",
    "## Prerequisites\n",
    "- Trained models from SageMaker (both trained and compiled)\n",
    "- AWS CLI configured with appropriate permissions\n",
    "- Access to AWS IoT Greengrass v2 service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f29c6-3b66-4398-99ce-4ef0fd1a3815",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "The Greengrass model component creation involves three main phases:\n",
    "\n",
    "### Phase 1: Model Artifact Preparation\n",
    "- Download trained model artifacts from S3\n",
    "- Extract and analyze model configuration\n",
    "- Create DDA-compatible manifest file\n",
    "\n",
    "### Phase 2: Directory Structure Setup\n",
    "- Download compiled model artifacts\n",
    "- Organize files in Greengrass-compatible structure\n",
    "- Package and upload to S3\n",
    "\n",
    "### Phase 3: Component Creation\n",
    "- Generate Greengrass component recipe\n",
    "- Create and validate the component\n",
    "- Monitor deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040d827-24a0-41cd-9077-ca917aab66b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required dependencies\n",
    "import os\n",
    "import tarfile\n",
    "import boto3\n",
    "import yaml\n",
    "import json\n",
    "import shutil\n",
    "import uuid\n",
    "import traceback\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Visual indicators for status messages\n",
    "green_check_mark = \"\\u2705\"  # ‚úÖ Success indicator\n",
    "error_mark = \"\\u274C\"       # ‚ùå Error indicator\n",
    "\n",
    "def print_tree(dir_path, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Display directory structure in tree format for better visualization.\n",
    "    \n",
    "    Args:\n",
    "        dir_path (str): Path to directory to display\n",
    "        prefix (str): Prefix for tree formatting\n",
    "    \"\"\"\n",
    "    items = os.listdir(dir_path)\n",
    "    \n",
    "    for index, item in enumerate(items):\n",
    "        # Format tree structure\n",
    "        if index == len(items) - 1:\n",
    "            print(prefix + \"‚îî‚îÄ‚îÄ \" + item)\n",
    "            new_prefix = prefix + \"    \"\n",
    "        else:\n",
    "            print(prefix + \"‚îú‚îÄ‚îÄ \" + item)\n",
    "            new_prefix = prefix + \"‚îÇ   \"\n",
    "        \n",
    "        # Recursively display subdirectories\n",
    "        item_path = os.path.join(dir_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print_tree(item_path, new_prefix)\n",
    "\n",
    "print(f\"{green_check_mark} Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853c7fe-0985-4d5b-a73d-304de846e952",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Phase 1: Model Artifact Preparation\n",
    "\n",
    "Download and process the trained model artifacts to create DDA-compatible components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64186c46-4a09-4836-883c-fea3ada28833",
   "metadata": {},
   "source": [
    "### Step 1.1: Specify Model Artifact Locations\n",
    "\n",
    "Provide S3 URIs for both trained (original) and compiled model artifacts.\n",
    "üí° Note: The trained model URI can be found in SageMaker AI -> Training ‚Üí Training jobs ‚Üí [Your Job Name] ‚Üí Output section\n",
    "üí° Note: The compiled model URI can be found in SageMaker AI -> Inference -> Compilation jobs -> [Your Job Name] -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdbcf8-a256-4e00-8c8e-2087c28fd1bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get S3 locations for model artifacts\n",
    "print(\"üì• Model Artifact Configuration\")\n",
    "print(\"Please provide S3 URIs for your trained models:\\n\")\n",
    "\n",
    "trained_model_artifacts = input(\"Enter S3 URI for trained model (from SageMaker training): \")\n",
    "compiled_model_artifacts = input(\"Enter S3 URI for compiled model (from SageMaker Inference -> Compilation): \")\n",
    "\n",
    "print(f\"\\n{green_check_mark} Model locations configured:\")\n",
    "print(f\"  Trained: {trained_model_artifacts}\")\n",
    "print(f\"  Compiled: {compiled_model_artifacts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8960d-9f1f-4dee-a96e-c960c94563ee",
   "metadata": {},
   "source": [
    "### Step 1.2: Setup Working Directory\n",
    "\n",
    "Create a clean workspace for model transformation and component preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d19fc2-de8b-4a47-9aa8-3da0362e196f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup working directory structure\n",
    "current_dir = os.getcwd()\n",
    "model_transformation_dir = os.path.join(current_dir, \"model_transformation\")\n",
    "\n",
    "try:\n",
    "    # Check if directory already exists\n",
    "    if os.path.isdir(model_transformation_dir):\n",
    "        print(f\"{error_mark} Directory {model_transformation_dir} already exists.\")\n",
    "        \n",
    "        # Prompt for cleanup confirmation\n",
    "        response = input(f\"\\nDelete existing directory? (yes/no): \").strip().lower()\n",
    "        if response == 'yes':\n",
    "            shutil.rmtree(model_transformation_dir)\n",
    "            print(f\"{green_check_mark} Cleaned up existing directory\")\n",
    "        else:\n",
    "            raise Exception(\"Directory cleanup declined\")\n",
    "    \n",
    "    # Create fresh directory structure\n",
    "    print(\"\\nüìÅ Creating workspace directory...\")\n",
    "    os.makedirs(model_transformation_dir, exist_ok=True)\n",
    "    \n",
    "    # Setup subdirectories\n",
    "    extract_dir = os.path.join(model_transformation_dir, 'model_folder')\n",
    "    model_file_name = trained_model_artifacts.split('/')[-1]\n",
    "    local_tar_dir = os.path.join(model_transformation_dir, model_file_name)\n",
    "    \n",
    "    print(f\"{green_check_mark} Workspace created at: {model_transformation_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n{error_mark} Setup failed: {str(e)}\")\n",
    "    print(\"Please clean the directory manually and retry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a44ed8-ee5f-44e0-9024-16418a3dc99f",
   "metadata": {},
   "source": [
    "### Step 1.3: Download Trained Model Artifacts\n",
    "\n",
    "Retrieve the original trained model from S3 for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f184b8-b569-416b-af6a-7b0fb5ef69ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download trained model artifacts from S3\n",
    "print(\"üì• Downloading trained model artifacts...\")\n",
    "!aws s3 cp {trained_model_artifacts} {model_transformation_dir}\n",
    "print(f\"{green_check_mark} Download completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bd585-3bd2-4d31-8367-5b67e116781a",
   "metadata": {},
   "source": [
    "### Step 1.4: Extract Model Archive\n",
    "\n",
    "Extract the trained model to access configuration files and model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d6581-3150-4604-b8e4-d3e4e29603cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the trained model archive\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    print(\"üì¶ Extracting model archive...\")\n",
    "    with tarfile.open(local_tar_dir, 'r:gz') as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "    \n",
    "    print(f\"{green_check_mark} Extraction completed at: {extract_dir}\")\n",
    "    print(\"\\nüìÇ Extracted contents:\")\n",
    "    print_tree(extract_dir)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"{error_mark} Extraction failed: {str(e)}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031337ce-d2ea-4d37-aec8-18ea5140864e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1.5: Process Model Configuration\n",
    "\n",
    "Read model configuration and manifest files to extract metadata needed for DDA integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781de6e6-572a-4df7-a2cb-6c68d02e4af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process model configuration and manifest files\n",
    "config_path = os.path.join(extract_dir, 'config.yaml')\n",
    "manifest_path = os.path.join(extract_dir, 'export_artifacts', 'manifest.json')\n",
    "export_artifacts_dir = os.path.join(extract_dir, 'export_artifacts')\n",
    "\n",
    "try:\n",
    "    print(\"‚öôÔ∏è Processing model configuration...\")\n",
    "    \n",
    "    # Read dataset configuration from YAML\n",
    "    with open(config_path, 'r') as yaml_file:\n",
    "        config_data = yaml.safe_load(yaml_file)\n",
    "        image_width = config_data['dataset']['image_width']\n",
    "        image_height = config_data['dataset']['image_height']\n",
    "    print(f\"{green_check_mark} Configuration loaded - Image size: {image_width}x{image_height}\")\n",
    "\n",
    "    # Read model manifest\n",
    "    with open(manifest_path, 'r') as json_file:\n",
    "        manifest_data = json.load(json_file)\n",
    "    print(f\"{green_check_mark} Manifest loaded\")\n",
    "    \n",
    "    # Locate PyTorch model file\n",
    "    pt_file = None\n",
    "    for file in os.listdir(export_artifacts_dir):\n",
    "        if file.endswith('.pt'):\n",
    "            pt_file = file\n",
    "            break\n",
    "    \n",
    "    if not pt_file:\n",
    "        raise FileNotFoundError(f\"{error_mark} No PyTorch (.pt) model file found\")\n",
    "    \n",
    "    print(f\"{green_check_mark} Model file located: {pt_file}\")\n",
    "\n",
    "    # Extract model metadata\n",
    "    input_shape = manifest_data.get('input_shape')\n",
    "    model_type = manifest_data[\"model_graph\"][\"stages\"][0][\"type\"]\n",
    "    \n",
    "    print(f\"üìä Model Details:\")\n",
    "    print(f\"  Type: {model_type}\")\n",
    "    print(f\"  Input Shape: {input_shape}\")\n",
    "    print(f\"  Image Dimensions: {image_width}x{image_height}\")\n",
    "\n",
    "    # Prepare compilable model configuration\n",
    "    compilable_model = {\n",
    "        \"filename\": pt_file,\n",
    "        \"data_input_config\": {\n",
    "            \"input\": input_shape\n",
    "        },\n",
    "        \"framework\": \"PYTORCH\"\n",
    "    }\n",
    "    \n",
    "    # Dataset configuration for DDA\n",
    "    dataset = {\n",
    "        \"image_width\": image_width,\n",
    "        \"image_height\": image_height\n",
    "    }\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"{error_mark} Configuration processing failed: {str(e)}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0f42f-9975-4947-950b-0be8c4bc7832",
   "metadata": {},
   "source": [
    "### Step 1.6: Generate DDA-Compatible Manifest\n",
    "\n",
    "Create a new manifest file optimized for DDA deployment and edge inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e3c09-35ae-4474-8dd3-8cf7dc9ef105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate DDA-compatible manifest file\n",
    "print(\"üìù Creating DDA-compatible manifest...\")\n",
    "\n",
    "# Construct new manifest with DDA-specific structure\n",
    "new_manifest_data = {\n",
    "    \"model_graph\": manifest_data[\"model_graph\"],\n",
    "    \"compilable_models\": [compilable_model],\n",
    "    \"dataset\": dataset\n",
    "}\n",
    "\n",
    "# Extract model name from manifest\n",
    "model_name = manifest_data[\"model_graph\"][\"stages\"][0][\"type\"]\n",
    "print(f\"üè∑Ô∏è Model type identified: {model_name}\")\n",
    "\n",
    "# Write the new manifest file\n",
    "new_manifest_path = os.path.join(extract_dir, 'export_artifacts', 'new_manifest.json')\n",
    "with open(new_manifest_path, 'w') as new_json_file:\n",
    "    json.dump(new_manifest_data, new_json_file, indent=4)\n",
    "\n",
    "print(f\"{green_check_mark} DDA manifest created at: {new_manifest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27512a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the generated manifest for verification\n",
    "print(\"üìÑ Generated DDA Manifest:\")\n",
    "print(\"=\" * 50)\n",
    "with open(new_manifest_path, 'r') as f:\n",
    "    print(f.read())\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df5558-f634-4dcd-b7e2-c355881f6f90",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Phase 2: Directory Structure Setup\n",
    "\n",
    "Organize compiled model artifacts in the structure required by AWS IoT Greengrass components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3980dbe-dab1-473c-bbf6-6a49abc76b69",
   "metadata": {},
   "source": [
    "### Step 2.1: Download Compiled Model Artifacts\n",
    "\n",
    "Retrieve the Neo-compiled model optimized for edge deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7047a6-84e4-4c36-984d-c3fce90bed63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup paths for compiled model processing\n",
    "file_name = compiled_model_artifacts.split(\"/\")[-1]\n",
    "extract_dir_prefix = os.path.join(model_transformation_dir, 'model_artifacts')\n",
    "compiled_extract_dir = os.path.join(extract_dir_prefix, model_name)\n",
    "local_compiled_tar = os.path.join(model_transformation_dir, file_name)\n",
    "\n",
    "print(f\"üì• Downloading compiled model: {file_name}\")\n",
    "!aws s3 cp {compiled_model_artifacts} {model_transformation_dir}\n",
    "print(f\"{green_check_mark} Compiled model downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31aba5e-268b-4d91-b8f3-6f06ee6afaa4",
   "metadata": {},
   "source": [
    "### Step 2.2: Extract Compiled Model\n",
    "\n",
    "Extract the compiled model artifacts into the appropriate directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408e572-b46f-48e9-91d1-c4bb859e9679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract compiled model artifacts\n",
    "print(\"üì¶ Extracting compiled model artifacts...\")\n",
    "os.makedirs(compiled_extract_dir, exist_ok=True)\n",
    "\n",
    "with tarfile.open(local_compiled_tar, 'r:gz') as tar:\n",
    "    tar.extractall(path=compiled_extract_dir)\n",
    "\n",
    "print(f\"{green_check_mark} Compiled model extracted to: {compiled_extract_dir}\")\n",
    "print(\"\\nüìÇ Compiled model structure:\")\n",
    "print_tree(compiled_extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4607f-be66-4725-8849-47a5078acca1",
   "metadata": {},
   "source": [
    "### Step 2.3: Integrate Manifest File\n",
    "\n",
    "Copy the DDA-compatible manifest to the compiled model directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072ac7d-8e24-4c3f-aedc-70b0af1c2f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy DDA manifest to the model artifacts directory\n",
    "manifest_destination = os.path.join(extract_dir_prefix, \"manifest.json\")\n",
    "shutil.copy(new_manifest_path, manifest_destination)\n",
    "\n",
    "print(f\"{green_check_mark} Manifest integrated into model structure\")\n",
    "print(f\"üìç Manifest location: {manifest_destination}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2e0df-a626-4865-ac1e-e4a61ef6b3d8",
   "metadata": {},
   "source": [
    "### Step 2.4: Package for Greengrass Deployment\n",
    "\n",
    "Create a ZIP archive of the complete model structure for Greengrass component deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd33003-a1e5-403f-96f6-e00776bdb79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package the complete model structure\n",
    "folder_to_zip = extract_dir_prefix\n",
    "uuid_for_model = str(uuid.uuid4()).split('-')[-1]\n",
    "uuid_greengrass = uuid_for_model + \"_greengrass_model_component\"\n",
    "output_zip = os.path.join(model_transformation_dir, uuid_greengrass)\n",
    "\n",
    "print(f\"üì¶ Creating Greengrass component package...\")\n",
    "print(f\"üÜî Component ID: {uuid_greengrass}\")\n",
    "print(\"\\nüìÇ Final directory structure:\")\n",
    "print_tree(folder_to_zip)\n",
    "\n",
    "# Create ZIP archive\n",
    "shutil.make_archive(output_zip, 'zip', folder_to_zip)\n",
    "print(f\"\\n{green_check_mark} Component package created: {output_zip}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9d816-dcfb-4879-b73c-0d3a28c75bdb",
   "metadata": {},
   "source": [
    "### Step 2.5: Configure S3 Upload Location\n",
    "\n",
    "Specify where to store the packaged model artifacts for Greengrass component access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd5478-2cf0-42d1-9a82-ecd6fb872d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure S3 storage location for model artifacts\n",
    "print(\"üóÇÔ∏è S3 Storage Configuration\")\n",
    "print(\"Configure where to store the packaged model artifacts:\\n\")\n",
    "\n",
    "default_model_name = f'model-{uuid_for_model}'\n",
    "s3_bucket_name = input(f\"Model identifier (default: {default_model_name}): \") or default_model_name\n",
    "s3_bucket_name = os.path.join(s3_bucket_name, uuid_greengrass + \".zip\")\n",
    "\n",
    "s3_uri = input(\"\\nS3 base URI (e.g., s3://your-bucket/path/): \")\n",
    "s3_uri = s3_uri.rstrip('/') + \"/model_artifacts/\"\n",
    "artifact_upload_location = os.path.join(s3_uri, s3_bucket_name)\n",
    "\n",
    "print(f\"\\nüìç Upload destination: {artifact_upload_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c8f55-2575-4109-91fa-f3f1e5562c73",
   "metadata": {},
   "source": [
    "### Step 2.6: Upload Model Artifacts\n",
    "\n",
    "Upload the packaged model component to S3 for Greengrass deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44805fde-2b68-433a-98fa-eee116383813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload packaged artifacts to S3\n",
    "print(f\"‚òÅÔ∏è Uploading model artifacts to S3...\")\n",
    "print(f\"üì§ Destination: {artifact_upload_location}\")\n",
    "\n",
    "!aws s3 cp {output_zip + '.zip'} {artifact_upload_location}\n",
    "\n",
    "print(f\"{green_check_mark} Model artifacts uploaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc88b7-c7f0-4781-adc5-0ff407713bec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 3: Greengrass Component Creation\n",
    "\n",
    "Create and deploy the AWS IoT Greengrass model component for edge inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6b2e8-d447-4d27-90c6-46ba04711df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.1: Component Configuration\n",
    "\n",
    "Define the Greengrass component parameters including name, version, and target platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac99f4-eef3-4d4e-9c62-bb13ca5745ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Component configuration parameters\n",
    "component_version_pattern = r'^\\d+\\.0+\\.0+$'  # Format: x.0.0\n",
    "platform_list = [\"aarch64\", \"amd64\"]\n",
    "\n",
    "print(\"‚öôÔ∏è Greengrass Component Configuration\")\n",
    "print(\"Configure the component details for deployment:\\n\")\n",
    "\n",
    "# Component name validation\n",
    "while True:\n",
    "    component_name = input(\"Component name (format: model-*, e.g., model-defect-classifier): \")\n",
    "    if component_name.startswith(\"model-\"):\n",
    "        print(f\"{green_check_mark} Component name: {component_name}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"{error_mark} Invalid format. Use 'model-*' naming convention\\n\")\n",
    "\n",
    "# Component version validation\n",
    "while True:\n",
    "    component_version = input(\"\\nComponent version (format: x.0.0, e.g., 1.0.0): \")\n",
    "    if re.match(component_version_pattern, component_version):\n",
    "        print(f\"{green_check_mark} Component version: {component_version}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"{error_mark} Invalid format. Use x.0.0 format\\n\")\n",
    "\n",
    "# Friendly name for the model\n",
    "model_friendly_name = input(\"\\nFriendly name (optional, press Enter to use component name): \") or component_name\n",
    "print(f\"{green_check_mark} Friendly name: {model_friendly_name}\")\n",
    "\n",
    "# Model artifacts URI\n",
    "model_artifacts_uri = input(\"\\nModel artifacts URI (press Enter to use uploaded location): \") or artifact_upload_location\n",
    "print(f\"{green_check_mark} Artifacts URI: {model_artifacts_uri}\")\n",
    "\n",
    "# Target platform validation\n",
    "while True:\n",
    "    platform = input(f\"\\nTarget platform {platform_list}: \")\n",
    "    if platform in platform_list:\n",
    "        print(f\"{green_check_mark} Target platform: {platform}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"{error_mark} Invalid platform. Choose from: {platform_list}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c195d90-0a19-4c86-8775-d6291e94eab2",
   "metadata": {},
   "source": [
    "### Step 3.2: Generate Component Recipe\n",
    "\n",
    "Create the Greengrass component recipe with proper lifecycle management and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599dd6b0-3463-4180-ba14-61c35c184261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate Greengrass component recipe\n",
    "print(\"üìã Generating component recipe...\")\n",
    "\n",
    "# Extract model archive name for component paths\n",
    "model_unarchived_path = model_artifacts_uri.split('/')[-1].split('.zip')[0]\n",
    "\n",
    "# Set platform-specific DDA LocalServer component dependency\n",
    "if platform == \"aarch64\":\n",
    "    local_server_component = \"aws.edgeml.dda.LocalServer.arm64\"\n",
    "elif platform == \"amd64\":\n",
    "    local_server_component = \"aws.edgeml.dda.LocalServer.amd64\"\n",
    "else:\n",
    "    local_server_component = \"aws.edgeml.dda.LocalServer\"\n",
    "\n",
    "print(f\"üîó DDA dependency: {local_server_component}\")\n",
    "\n",
    "# Construct the complete component recipe\n",
    "recipe = {\n",
    "    \"RecipeFormatVersion\": \"2020-01-25\",\n",
    "    \"ComponentName\": component_name,\n",
    "    \"ComponentVersion\": component_version,\n",
    "    \"ComponentType\": \"aws.greengrass.generic\",\n",
    "    \"ComponentPublisher\": \"Amazon Lookout for Vision\",\n",
    "    \n",
    "    # Component configuration\n",
    "    \"ComponentConfiguration\": {\n",
    "        \"DefaultConfiguration\": {\n",
    "            \"Autostart\": False,\n",
    "            \"PYTHONPATH\": \"/usr/bin/python3.9\",\n",
    "            \"ModelName\": model_friendly_name\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Dependencies on DDA LocalServer component\n",
    "    \"ComponentDependencies\": {\n",
    "        local_server_component: {\n",
    "            \"VersionRequirement\": \"^1.0.0\",\n",
    "            \"DependencyType\": \"HARD\"\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Platform-specific manifests\n",
    "    \"Manifests\": [\n",
    "        {\n",
    "            \"Platform\": {\n",
    "                \"os\": \"linux\",\n",
    "                \"architecture\": platform\n",
    "            },\n",
    "            \n",
    "            # Lifecycle management\n",
    "            \"Lifecycle\": {\n",
    "                \"Startup\": {\n",
    "                    \"Script\": f\"python3 /aws_dda/model_convertor.py --unarchived_model_path {{artifacts:decompressedPath}}/{model_unarchived_path}/ --model_version {component_version} --model_name {component_name}\",\n",
    "                    \"Timeout\": 900,\n",
    "                    \"requiresPrivilege\": True,\n",
    "                    \"runWith\": {\n",
    "                        \"posixUser\": \"root\"\n",
    "                    }\n",
    "                },\n",
    "                \"Shutdown\": {\n",
    "                    \"Script\": f\"python3 /aws_dda/convert_model_cleanup.py --model_name {component_name}\",\n",
    "                    \"Timeout\": 900,\n",
    "                    \"requiresPrivilege\": True,\n",
    "                    \"runWith\": {\n",
    "                        \"posixUser\": \"root\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            # Model artifacts configuration\n",
    "            \"Artifacts\": [\n",
    "                {\n",
    "                    \"Uri\": model_artifacts_uri,\n",
    "                    \"Digest\": \"\",  # Will be calculated by Greengrass\n",
    "                    \"Algorithm\": \"SHA-256\",\n",
    "                    \"Unarchive\": \"ZIP\",\n",
    "                    \"Permission\": {\n",
    "                        \"Read\": \"ALL\",\n",
    "                        \"Execute\": \"ALL\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"Lifecycle\": {}\n",
    "}\n",
    "\n",
    "print(f\"{green_check_mark} Component recipe generated\")\n",
    "print(f\"üì¶ Component: {component_name} v{component_version}\")\n",
    "print(f\"üèóÔ∏è Platform: {platform}\")\n",
    "print(f\"üìç Artifacts: {model_artifacts_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2253e-1ad2-4c3f-8ec6-a1b4c7576f2d",
   "metadata": {},
   "source": [
    "### Step 3.3: Deploy Greengrass Component\n",
    "\n",
    "Create the Greengrass component and monitor its deployment status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335635d4-8025-4a54-9949-c03845a87e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and deploy the Greengrass component\n",
    "client = boto3.client('greengrassv2')\n",
    "\n",
    "print(\"üöÄ Creating Greengrass model component...\")\n",
    "print(f\"üìã Recipe: {json.dumps(recipe, indent=2)}\\n\")\n",
    "\n",
    "try:\n",
    "    # Create the component version\n",
    "    response = client.create_component_version(\n",
    "        inlineRecipe=json.dumps(recipe)\n",
    "    )\n",
    "    \n",
    "    model_component_arn = response.get('arn')\n",
    "    print(f\"{green_check_mark} Component created successfully!\")\n",
    "    print(f\"üÜî Component ARN: {model_component_arn}\")\n",
    "    \n",
    "    # Monitor component status\n",
    "    print(\"\\n‚è≥ Monitoring component status...\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"üîç Checking component status...\")\n",
    "        \n",
    "        response = client.describe_component(arn=model_component_arn)\n",
    "        status = response['status']['componentState']\n",
    "        message = response['status'].get('message', 'No additional message')\n",
    "        errors = response['status'].get('errors', [])\n",
    "        \n",
    "        # Check if component is ready\n",
    "        if status not in [\"REQUESTED\", \"IN_PROGRESS\"]:\n",
    "            if status == \"DEPLOYABLE\":\n",
    "                print(f\"\\n{green_check_mark} Component is ready for deployment!\")\n",
    "                print(f\"üìä Final Status: {status}\")\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è Component Status: {status}\")\n",
    "            \n",
    "            # Display additional details if available\n",
    "            if message != 'NONE' and message != 'No additional message':\n",
    "                print(f\"üí¨ Message: {message}\")\n",
    "            if errors:\n",
    "                print(f\"‚ùå Errors: {errors}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"‚è≥ Status: {status} - Checking again in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"{error_mark} Component creation failed: {str(e)}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ef3d9-54f7-4a0e-855b-2ff4fad0b713",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "üéâ **Greengrass Model Component Setup Complete!**\n",
    "\n",
    "### What was accomplished:\n",
    "\n",
    "1. **‚úÖ Model Processing**: Downloaded and processed SageMaker-trained models\n",
    "2. **‚úÖ Manifest Creation**: Generated DDA-compatible manifest files\n",
    "3. **‚úÖ Artifact Packaging**: Created Greengrass-ready component packages\n",
    "4. **‚úÖ Component Deployment**: Successfully deployed to AWS IoT Greengrass\n",
    "\n",
    "### Component Details:\n",
    "- **Name**: `{component_name if 'component_name' in locals() else 'N/A'}`\n",
    "- **Version**: `{component_version if 'component_version' in locals() else 'N/A'}`\n",
    "- **Platform**: `{platform if 'platform' in locals() else 'N/A'}`\n",
    "- **Model Type**: `{model_name if 'model_name' in locals() else 'N/A'}`\n",
    "\n",
    "### Next Steps:\n",
    "1. **Deploy to Edge Device**: Use AWS IoT Greengrass console to deploy the component\n",
    "2. **Configure DDA**: Set up the Defect Detection Application to use this model\n",
    "3. **Test Inference**: Validate model performance on edge device\n",
    "4. **Monitor Performance**: Use CloudWatch for component monitoring\n",
    "\n",
    "### Useful Commands:\n",
    "```bash\n",
    "# List components\n",
    "aws greengrassv2 list-components\n",
    "\n",
    "# Create deployment\n",
    "aws greengrassv2 create-deployment --target-arn <thing-arn> --components '{\"<component-name>\":{\"componentVersion\":\"<version>\"}}'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
