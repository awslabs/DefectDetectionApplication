{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0fa16f",
   "metadata": {},
   "source": [
    "## SageMaker Training for DDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2fa15",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "1. Note: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using **Amazon SageMaker**.\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "   \n",
    "   A. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used:\n",
    "   \n",
    "        a. aws-marketplace:ViewSubscriptions\n",
    "        b. aws-marketplace:Unsubscribe\n",
    "        c. aws-marketplace:Subscribe\n",
    "   \n",
    "   B: or your AWS account has a subscription to:[Computer Vision Defect Detection Model](https://aws.amazon.com/marketplace/pp/prodview-j72hhmlt6avp6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e78bd",
   "metadata": {},
   "source": [
    "### Subscribe to the algorithm\n",
    "\n",
    "To subscribe to the algorithm:\n",
    "\n",
    "1. Open the algorithm listing page: [Computer Vision Defect Detection Model](https://aws.amazon.com/marketplace/pp/prodview-j72hhmlt6avp6).\n",
    "1. On the AWS Marketplace listing, click on Continue to subscribe button.\n",
    "1. On the Subscribe to this software page, review and click on \"Accept Offer\" if you agree with EULA, pricing, and support terms.\n",
    "1. Once you click on Continue to configuration button and then choose a region, you will see a Product Arn. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the algorithm name and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this to use subscribed SageMaker algorithm\n",
    "algorithm_name = \"<Customer to specify the algorithm name after subscribtion>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a681a",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "# Project name would be used as part of s3 output path\n",
    "project = \"LFV-public-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca0d53",
   "metadata": {},
   "source": [
    "### Prepare data - No need to go thru this\n",
    "Prepare mansifest file and download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb531a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://lookoutvision-us-east-1-0e205be246/getting-started/manifests/train_class.manifest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://lookoutvision-us-east-1-0e205be246/getting-started/manifests/train_segmentation.manifest ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715cdaa",
   "metadata": {},
   "source": [
    "Dataset is from LFV getting start - https://docs.aws.amazon.com/lookout-for-vision/latest/developer-guide/getting-started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://docs.aws.amazon.com/lookout-for-vision/latest/developer-guide/samples/getting-started.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d5faf",
   "metadata": {},
   "source": [
    "### Create IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c284ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = boto3.client('iam')\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the IAM role\n",
    "role_name = \"SageMakerExecutionRole\"\n",
    "\n",
    "response = iam_client.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "    Description=\"IAM role with full S3 and SageMaker access\"\n",
    ")\n",
    "\n",
    "sm_role_arn = response['Role']['Arn']\n",
    "print(f\"Role created with ARN: {sm_role_arn}\")\n",
    "\n",
    "# Attach policies for full S3 and SageMaker access\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    ")\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\"\n",
    ")\n",
    "print(\"Attached S3 full access and SageMaker full access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad86092",
   "metadata": {},
   "source": [
    "## Classification Model\n",
    "Start training job for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "sagemaker = boto3.Session(region_name=region).client(\"sagemaker\")\n",
    "classification_training_job_name = 'LFV-classification-'+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019056c",
   "metadata": {},
   "source": [
    "To use robust model feature for classification model:\n",
    "```\n",
    "HyperParameters={\n",
    "    'ModelType': 'classification-robust',\n",
    "    'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label',\n",
    "    'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label'\n",
    "},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9990c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker.create_training_job(\n",
    "    TrainingJobName=classification_training_job_name,\n",
    "    HyperParameters={\n",
    "        'ModelType': 'classification',\n",
    "        'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label',\n",
    "        'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label'\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'AlgorithmName': algorithm_name,\n",
    "        'TrainingInputMode': 'File',\n",
    "        'EnableSageMakerMetricsTimeSeries': False\n",
    "    },\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'training',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'AugmentedManifestFile',\n",
    "                    'S3Uri': 's3://lookoutvision-us-east-1-0e205be246/getting-started/manifests/train_class.manifest',\n",
    "                    'S3DataDistributionType': 'ShardedByS3Key',\n",
    "                    'AttributeNames': [\n",
    "                        'source-ref',\n",
    "                        'anomaly-label-metadata',\n",
    "                        'anomaly-label'\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'RecordIO',\n",
    "            'InputMode': 'Pipe'\n",
    "        },\n",
    "    ],\n",
    "    OutputDataConfig={'S3OutputPath': 's3://'+bucket+'/'+project+'/output'},\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.g4dn.2xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 20\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 7200\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    training_response = sagemaker.describe_training_job(\n",
    "        TrainingJobName=classification_training_job_name\n",
    "    )\n",
    "    if training_response['TrainingJobStatus'] == 'InProgress':\n",
    "        print(\".\", end='')\n",
    "    elif training_response['TrainingJobStatus'] == 'Completed':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif training_response['TrainingJobStatus'] == 'Failed':\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38efdd",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8031e",
   "metadata": {},
   "source": [
    "## Segmentation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e39f56",
   "metadata": {},
   "source": [
    "Start traning job for segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de783648",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_training_job_name = 'LFV-segmentation-'+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d291b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.Session(region_name=region).client(\"sagemaker\")\n",
    "response = sagemaker.create_training_job(\n",
    "    TrainingJobName=segmentation_training_job_name,\n",
    "    HyperParameters={\n",
    "        # To use robust model feature, change \"ModelType\" to \"segmentation-robust\"\n",
    "        'ModelType': 'segmentation',\n",
    "        'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref',\n",
    "        'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref'\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'AlgorithmName': algorithm_name,\n",
    "        'TrainingInputMode': 'File',\n",
    "        'EnableSageMakerMetricsTimeSeries': False\n",
    "    },\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'training',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'AugmentedManifestFile',\n",
    "                    'S3Uri': 's3://lookoutvision-us-east-1-0e205be246/getting-started/manifests/train_segmentation.manifest',\n",
    "                    'S3DataDistributionType': 'ShardedByS3Key',\n",
    "                    'AttributeNames': [\n",
    "                        'source-ref',\n",
    "                        'anomaly-label-metadata',\n",
    "                        'anomaly-label',\n",
    "                        'anomaly-mask-ref-metadata',\n",
    "                        'anomaly-mask-ref'\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'RecordIO',\n",
    "            'InputMode': 'Pipe'\n",
    "        },\n",
    "    ],\n",
    "    OutputDataConfig={'S3OutputPath': 's3://'+bucket+'/'+project+'/output'},\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.g4dn.2xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 20\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 7200\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    training_response = sagemaker.describe_training_job(\n",
    "        TrainingJobName=segmentation_training_job_name\n",
    "    )\n",
    "    if training_response['TrainingJobStatus'] == 'InProgress':\n",
    "        print(\".\", end='')\n",
    "    elif training_response['TrainingJobStatus'] == 'Completed':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif training_response['TrainingJobStatus'] == 'Failed':\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348560fc",
   "metadata": {},
   "source": [
    "To use Segmentation head only, use hyper parameters like following:\n",
    "```\n",
    "HyperParameters={\n",
    "    'ModelType': 'segmentation',\n",
    "    'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref',\n",
    "    'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref',\n",
    "    'classification_logic': 'seg_head'\n",
    "},\n",
    "```\n",
    "\n",
    "To enable robust model feature for segmentation model:\n",
    "```\n",
    "HyperParameters={\n",
    "    'ModelType': 'segmentation-robust',\n",
    "    'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref',\n",
    "    'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref'\n",
    "},\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f7443",
   "metadata": {},
   "source": [
    "***********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13f24b",
   "metadata": {},
   "source": [
    "## Compilation job - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1951b",
   "metadata": {},
   "source": [
    "After training job is completed, we will create a sagemaker compilation job. During compilation job we will sepecify the target device we will run on along with DDA edge application.\n",
    "\n",
    "Since SageMaker compilation job expects only one PyTorch model file, we could not use the training job output artifact directly. \n",
    "\n",
    "Prepare model for compilation:\n",
    "1. download trained model\n",
    "2. unzip and tar the mochi.pt file to mochi.tar.gz\n",
    "3. upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_class = sagemaker.describe_training_job(TrainingJobName=classification_training_job_name)\n",
    "output_model_path = res_class['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d3bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(output_model_path)\n",
    "output_bucket = parsed_url.netloc\n",
    "output_key = parsed_url.path.lstrip('/')\n",
    "print(output_bucket)\n",
    "print(output_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "path = \"./classification\"\n",
    "Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the .tar.gz file from S3\n",
    "input_tar_gz = os.path.join(path, 'model.tar.gz')\n",
    "s3_client.download_file(output_bucket, output_key, input_tar_gz)\n",
    "\n",
    "# Extract the contents of the .tar.gz file\n",
    "extract_dir = os.path.join(path, 'extracted')\n",
    "Path(extract_dir).mkdir(parents=True, exist_ok=True)\n",
    "with tarfile.open(input_tar_gz, 'r:gz') as tar:\n",
    "    tar.extractall(path=extract_dir)\n",
    "print(f\"Extracted {input_tar_gz} to {extract_dir}.\")\n",
    "\n",
    "# Find the file with \"mochi.pt\" in its name\n",
    "model_file = os.path.join(extract_dir, 'mochi.pt')\n",
    "if model_file is None:\n",
    "    raise Exception(\"No mochi.pt file found.\")\n",
    "\n",
    "print(f\"Found model file: {model_file}\")\n",
    "\n",
    "# Create a new .tar.gz file with the model.pt file\n",
    "output_tar_gz = os.path.join(path, 'classification.tar.gz')\n",
    "with tarfile.open(output_tar_gz, \"w:gz\") as tar:\n",
    "    tar.add(model_file, arcname=os.path.basename(model_file))\n",
    "print(f\"Created tar.gz file {output_tar_gz} with {model_file}.\")\n",
    "\n",
    "# Upload the new .tar.gz file to S3\n",
    "target_key = output_key.rsplit('/', 1)[0] + '/classification.tar.gz'\n",
    "s3_client.upload_file(output_tar_gz, output_bucket, target_key)\n",
    "print(f\"Uploaded {output_tar_gz} to bucket {output_bucket} with key {target_key}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4f4c1",
   "metadata": {},
   "source": [
    "### Target Device: Jetson xavier Jetpack4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_job_name = \"class-xavier-gpu-\"+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd955e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_model_path = f\"s3://{output_bucket}/{target_key}\"\n",
    "print(f\"Compressed model path {compressed_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21225218",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_response = sagemaker.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputConfig={\n",
    "        'S3Uri': compressed_model_path,\n",
    "        'DataInputConfig': '{\"input_shape\": [1,3,672,480]}',\n",
    "        'Framework': 'PYTORCH',\n",
    "        'FrameworkVersion': '1.8'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': 's3://'+bucket+'/'+project+'/compilation_output',\n",
    "        'TargetPlatform': {\n",
    "            'Os': 'LINUX',\n",
    "            'Arch': 'ARM64',\n",
    "            'Accelerator': 'NVIDIA'\n",
    "        },\n",
    "        'CompilerOptions': '{\"cuda-ver\": \"10.2\",\"gpu-code\": \"sm_72\",\"trt-ver\": \"8.2.1\"}'\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 3600\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    compile_response = sagemaker.describe_compilation_job(\n",
    "        CompilationJobName=compilation_job_name\n",
    "    )\n",
    "    if compile_response['CompilationJobStatus'] == 'INPROGRESS':\n",
    "        print(\".\", end='')\n",
    "    elif compile_response['CompilationJobStatus'] == 'STARTING':\n",
    "        print(\"*\", end='')\n",
    "    elif compile_response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif compile_response['CompilationJobStatus'] == 'FAILED':\n",
    "        print(\"Failed\")\n",
    "        print(compile_response['FailureReason'])\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2499f",
   "metadata": {},
   "source": [
    "### Target Device: x86 cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_job_name = \"class-x86-cpu-\"+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_response = sagemaker.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputConfig={\n",
    "        'S3Uri': compressed_model_path,\n",
    "        'DataInputConfig': '{\"input_shape\": [1,3,672,480]}',\n",
    "        'Framework': 'PYTORCH',\n",
    "        'FrameworkVersion': '1.8'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': 's3://'+bucket+'/'+project+'/compilation_output',\n",
    "        'TargetPlatform': {\n",
    "            'Os': 'LINUX',\n",
    "            'Arch': 'X86_64'\n",
    "        }\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 3600\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    compile_response = sagemaker.describe_compilation_job(\n",
    "        CompilationJobName=compilation_job_name\n",
    "    )\n",
    "    if compile_response['CompilationJobStatus'] == 'INPROGRESS':\n",
    "        print(\".\", end='')\n",
    "    elif compile_response['CompilationJobStatus'] == 'STARTING':\n",
    "        print(\"*\", end='')\n",
    "    elif compile_response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif compile_response['CompilationJobStatus'] == 'FAILED':\n",
    "        print(\"Failed\")\n",
    "        print(compile_response['FailureReason'])\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db50db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0821bee",
   "metadata": {},
   "source": [
    "### Target Device: arm cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_arm_cpu = \"class-arm-cpu-\"+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea17d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_arm_response = sagemaker.create_compilation_job(\n",
    "    CompilationJobName=compilation_arm_cpu,\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputConfig={\n",
    "        'S3Uri': compressed_model_path,\n",
    "        'DataInputConfig': '{\"input_shape\": [1,3,672,480]}',\n",
    "        'Framework': 'PYTORCH',\n",
    "        'FrameworkVersion': '1.8'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': 's3://'+bucket+'/'+project+'/compilation_output',\n",
    "        'TargetPlatform': {\n",
    "            'Os': 'LINUX',\n",
    "            'Arch': 'ARM64'\n",
    "        }\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 3600\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    create_arm_response = sagemaker.describe_compilation_job(\n",
    "        CompilationJobName=compilation_arm_cpu\n",
    "    )\n",
    "    if create_arm_response['CompilationJobStatus'] == 'INPROGRESS':\n",
    "        print(\".\", end='')\n",
    "    elif create_arm_response['CompilationJobStatus'] == 'STARTING':\n",
    "        print(\"*\", end='')\n",
    "    elif create_arm_response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif create_arm_response['CompilationJobStatus'] == 'FAILED':\n",
    "        print(\"Failed\")\n",
    "        print(create_arm_response['FailureReason'])\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_arm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b2b74",
   "metadata": {},
   "source": [
    "## Compilation job - Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c7e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_training = segmentation_training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ab9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_seg = sagemaker.describe_training_job(TrainingJobName=seg_training)\n",
    "seg_output_model_path = res_seg['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(seg_output_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3e0da",
   "metadata": {},
   "source": [
    "Prepare model for compilation:\n",
    "1. download trained model\n",
    "2. unzip and tar the mochi.pt file to mochi.tar.gz\n",
    "3. upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda57cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(seg_output_model_path)\n",
    "output_bucket = parsed_url.netloc\n",
    "output_key = parsed_url.path.lstrip('/')\n",
    "print(output_bucket)\n",
    "print(output_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "path = \"./segmentation\"\n",
    "Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the .tar.gz file from S3\n",
    "input_tar_gz = os.path.join(path, 'model.tar.gz')\n",
    "s3_client.download_file(output_bucket, output_key, input_tar_gz)\n",
    "\n",
    "# Extract the contents of the .tar.gz file\n",
    "extract_dir = os.path.join(path, 'extracted')\n",
    "Path(extract_dir).mkdir(parents=True, exist_ok=True)\n",
    "with tarfile.open(input_tar_gz, 'r:gz') as tar:\n",
    "    tar.extractall(path=extract_dir)\n",
    "print(f\"Extracted {input_tar_gz} to {extract_dir}.\")\n",
    "\n",
    "# Find the file with \"mochi.pt\" in its name\n",
    "model_file = os.path.join(extract_dir, 'mochi.pt')\n",
    "if model_file is None:\n",
    "    raise Exception(\"No mochi.pt file found.\")\n",
    "\n",
    "print(f\"Found model file: {model_file}\")\n",
    "\n",
    "# Create a new .tar.gz file with the model.pt file\n",
    "output_tar_gz = os.path.join(path, 'segmentation.tar.gz')\n",
    "with tarfile.open(output_tar_gz, \"w:gz\") as tar:\n",
    "    tar.add(model_file, arcname=os.path.basename(model_file))\n",
    "print(f\"Created tar.gz file {output_tar_gz} with {model_file}.\")\n",
    "\n",
    "# Upload the new .tar.gz file to S3\n",
    "target_key = output_key.rsplit('/', 1)[0] + '/segmentation.tar.gz'\n",
    "s3_client.upload_file(output_tar_gz, output_bucket, target_key)\n",
    "print(f\"Uploaded {output_tar_gz} to bucket {output_bucket} with key {target_key}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_job = \"seg-x86-cpu-\"+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497382f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"s3://{output_bucket}/{target_key}\"\n",
    "print(f\"Compressed model path {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfaed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_x86_response = sagemaker.create_compilation_job(\n",
    "    CompilationJobName=compilation_job,\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputConfig={\n",
    "        'S3Uri': model_path,\n",
    "        'DataInputConfig': '{\"input_shape\": [1,3,768,576]}',\n",
    "        'Framework': 'PYTORCH',\n",
    "        'FrameworkVersion': '1.8'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': 's3://'+bucket+'/'+project+'/compilation_output',\n",
    "        'TargetPlatform': {\n",
    "            'Os': 'LINUX',\n",
    "            'Arch': 'X86_64'\n",
    "        }\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 3600\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    create_response = sagemaker.describe_compilation_job(\n",
    "        CompilationJobName=compilation_job\n",
    "    )\n",
    "    if create_response['CompilationJobStatus'] == 'INPROGRESS':\n",
    "        print(\".\", end='')\n",
    "    elif create_response['CompilationJobStatus'] == 'STARTING':\n",
    "        print(\"*\", end='')\n",
    "    elif create_response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif create_response['CompilationJobStatus'] == 'FAILED':\n",
    "        print(\"Failed\")\n",
    "        print(create_response['FailureReason'])\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed0728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
