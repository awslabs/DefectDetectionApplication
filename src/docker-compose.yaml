version: "3.0"
services:
  # NVIDIA Jetson devices (Xavier, Orin) - ARM64 with Tegra GPU
  backend_tegra_gpu_enabled:
    network_mode: "host"
    build: ./backend
    image: flask-app
    privileged: true
    expose:
      - "5000"
      - "5443"
    volumes:
      - /aws_dda:/aws_dda
      - /tmp:/tmp
      - /dev/shm:/dev/shm
      - /usr/local/cuda:/usr/local/cuda/
      - /usr/lib/aarch64-linux-gnu/tegra:/usr/lib/aarch64-linux-gnu/tegra
    environment:
      - OS=$OS
      - DDA_SYSTEM_USER_ID=$DDA_SYSTEM_USER_ID
      - DDA_SYSTEM_GROUP_ID=$DDA_SYSTEM_GROUP_ID
      - DDA_ADMIN_USER_ID=$DDA_ADMIN_USER_ID
      - DDA_ADMIN_GROUP_ID=$DDA_ADMIN_GROUP_ID
      - AWS_REGION
      - SVCUID
      - AWS_GG_NUCLEUS_DOMAIN_SOCKET_FILEPATH_FOR_COMPONENT
      - AWS_CONTAINER_AUTHORIZATION_TOKEN
      - AWS_CONTAINER_CREDENTIALS_FULL_URI
      - AWS_IOT_THING_NAME
      - COMPONENT_WORK_PATH
      - KERNEL_ROOT_PATH
      - INFERENCE_COMPONENT_DECOMPRESED_PATH
      - LOCAL_SERVER_COMPONENT_DECOMPRESSED_PATH
      - JETSON_CUDA=$JETSON_CUDA
      - JETSON_TENSORRT=$JETSON_TENSORRT
      - CUDA_HOME=/usr/local/cuda/
      - LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_HOME/lib64/:/usr/lib/aarch64-linux-gnu/tegra:/usr/local/cuda/targets/aarch64-linux/lib/
      - GRPC_POLL_STRATEGY=poll
      - GRPC_ENABLE_FORK_SUPPORT=1
      - PYTHONPATH=/opt/tritonserver/backends/python:/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles: [tegra]
  # CPU-only systems (x86_64, ARM64) - no GPU acceleration
  backend_generic:
    network_mode: "host"
    build: ./backend
    image: flask-app
    privileged: true
    expose:
      - "5000"
      - "5443"
      - "8000"
      - "8001"
      - "80002"
    volumes:
      - /aws_dda:/aws_dda
      - /tmp:/tmp
      - /dev/shm:/dev/shm
    environment:
      - DDA_SYSTEM_USER_ID=$DDA_SYSTEM_USER_ID
      - DDA_SYSTEM_GROUP_ID=$DDA_SYSTEM_GROUP_ID
      - DDA_ADMIN_USER_ID=$DDA_ADMIN_USER_ID
      - DDA_ADMIN_GROUP_ID=$DDA_ADMIN_GROUP_ID
      - AWS_REGION
      - SVCUID
      - AWS_GG_NUCLEUS_DOMAIN_SOCKET_FILEPATH_FOR_COMPONENT
      - AWS_CONTAINER_AUTHORIZATION_TOKEN
      - AWS_CONTAINER_CREDENTIALS_FULL_URI
      - AWS_IOT_THING_NAME
      - COMPONENT_WORK_PATH
      - KERNEL_ROOT_PATH
      - INFERENCE_COMPONENT_DECOMPRESED_PATH
      - LOCAL_SERVER_COMPONENT_DECOMPRESSED_PATH
      - JETSON_CUDA=$JETSON_CUDA
      - JETSON_TENSORRT=$JETSON_TENSORRT
      - LD_LIBRARY_PATH=$LD_LIBRARY_PATH
      - GRPC_POLL_STRATEGY=poll
      - GRPC_ENABLE_FORK_SUPPORT=1
      - PYTHONPATH=/opt/tritonserver/backends/python:/
    profiles: [generic]
  # x86_64 systems with NVIDIA GPU (Tesla T4, RTX, etc.)
  backend_x86_cuda:
    network_mode: "host"
    build: ./backend
    image: flask-app
    privileged: true
    expose:
      - "5000"
      - "5443"
      - "8000"
      - "8001"
      - "80002"
    volumes:
      - /aws_dda:/aws_dda
      - /tmp:/tmp
      - /dev/shm:/dev/shm
      - /usr/local/cuda:/usr/local/cuda:ro
      - /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:ro
    environment:
      - DDA_SYSTEM_USER_ID=$DDA_SYSTEM_USER_ID
      - DDA_SYSTEM_GROUP_ID=$DDA_SYSTEM_GROUP_ID
      - DDA_ADMIN_USER_ID=$DDA_ADMIN_USER_ID
      - DDA_ADMIN_GROUP_ID=$DDA_ADMIN_GROUP_ID
      - AWS_REGION
      - SVCUID
      - AWS_GG_NUCLEUS_DOMAIN_SOCKET_FILEPATH_FOR_COMPONENT
      - AWS_CONTAINER_AUTHORIZATION_TOKEN
      - AWS_CONTAINER_CREDENTIALS_FULL_URI
      - AWS_IOT_THING_NAME
      - COMPONENT_WORK_PATH
      - KERNEL_ROOT_PATH
      - INFERENCE_COMPONENT_DECOMPRESED_PATH
      - LOCAL_SERVER_COMPONENT_DECOMPRESSED_PATH
      - JETSON_CUDA=$JETSON_CUDA
      - JETSON_TENSORRT=$JETSON_TENSORRT
      - CUDA_HOME=/usr/local/cuda
      - LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64
      - GRPC_POLL_STRATEGY=poll
      - GRPC_ENABLE_FORK_SUPPORT=1
      - PYTHONPATH=/opt/tritonserver/backends/python:/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles: [x86_cuda]
  # React web interface - runs on all configurations
  frontend:
    build: ./frontend
    image: react-webapp
    ports:
      - "3000:80"
      - "3443:443"
    volumes:
      - /aws_dda:/aws_dda
